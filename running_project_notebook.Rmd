---
title: "R Notebook"
output: html_notebook
---

I'd like to see if there are any patterns in my running pace and if so use them to make predictions about my pace in future runs. I have about five years of running data stored in Strava, so I exported this data, deleted some irrelevant, redundant, or personal columns, and will import and clean it up here.

```{r setup}

#Let's start by loading necessary packages

library(tidyverse)
library(lubridate)
library(zoo)
library(modelr)

# Import the dataset

activities <- read_csv("activities.csv",
                       col_types = cols(
  `Activity ID` = col_double(),
  `Activity Date` = col_character(),
  `Activity Name` = col_character(),
  `Activity Type` = col_character(),
  `Elapsed Time` = col_double(),
  Distance = col_double(),
  Commute = col_logical(),
  `Moving Time` = col_double(),
  `Max Speed` = col_double(),
  `Elevation Gain` = col_double(),
  `Elevation Loss` = col_double(),
  `Elevation Low` = col_double(),
  `Elevation High` = col_double(),
  `Max Grade` = col_double(),
  `Average Grade` = col_double()
                                )
                       )

# I'm only intersted in running for now, so I'm going to filter out any other activities (which I haven't recorded as consistently)

activities <- activities %>%
        filter(`Activity Type` == "Run") %>%
        mutate(date = mdy_hms(`Activity Date`)) %>%
        mutate(date = with_tz(date, "America/New_York")) %>%
        mutate(date = as_date(date))

```

```{r head_and_tail}
head(activities)

tail(activities)
```

So we're left with 708 runs recorded between July 17, 2015 and June 19, 2020. Some of the columns that might contribute to my speed include "Activity Date" (how old I was), "Distance," and "Elevation Gain." I could also estimate how well trained I was at any particular moment (say, how much I had run in the previous twelve weeks), and my recovery status (say, how much I had run in the previous two days). 

Let's start by looking at my pace over time to see if any patterns leap out.

```{r pace}

# Calculate pace and plot changes over time
# "Distance" is in km and "Moving Time" is in seconds
# So we get a pace of seconds / km

activities <- activities %>%
        mutate(pace = `Moving Time` / Distance)

ggplot(activities, mapping = aes(x = date, y = pace)) +
        geom_point()

```

I wonder what's going on with the outliers where I'm much faster or slower than usual

```{r slow}
activities %>%
        filter(pace > 450)
```

The slowest run is a trail run with a big elevation gain, so we should be able to account for it with regression analysis later on. The second slowest run I was accompanying my child on a fun run, so it doesn't indicate my own efforts. I never go on a runs that short, so I can probably eliminate some uncharacteristic data by removing distances of less than two kilometers without losing any useful data.

```{r fast}
activities %>%
        filter(pace < 300)
```

At least two of the fast runs are races, but one of them looks like a misclassified bike ride. I don't think I can run that fast! Let's remove it from the data set and replot the data.

```{r filter}
activities <- activities %>%
        filter(pace > 200) %>%
        filter(Distance > 2)
        
        ggplot(activities, mapping = aes(x = date, y = pace)) +
        geom_point()
```

It does look like I might be getting slightly slower over time. Is it aging or something else? Let's fit a model to the data to see what we're working with.

```{r date_model}
mod_date <- lm(pace ~ date, activities)
mod_date
anova(mod_date)
ggplot(activities, mapping = aes(x = date, y = pace)) +
        geom_point() +
        geom_abline(slope = 0.03355, intercept = -211.19030)
```

I've definitely been getting slower over the past five years, but is it just the passage of time or are their other explanations?

Distance seems like it would be an important factor for pace. Let's take a look:

```{r distance_model}

mod_distance <- lm(pace ~ Distance, activities)
mod_distance
anova(mod_distance)
ggplot(activities, mapping = aes(x = Distance, y = pace)) +
        geom_point() +
        geom_abline(slope = 0.5395, intercept = 373.0588)

```

Distance certainly makes a difference, but not as much as I might have thought. The three longest runs are marathons, which means I was well-trained and ready to race.

Let's consider elevation gain:

```{r elevation_model}

activities <- activities %>%
        rename(elevation_gain = `Elevation Gain`)
mod_elevation <- lm(pace ~ elevation_gain, activities)
mod_elevation
anova(mod_elevation)
ggplot(activities, mapping = aes(x = elevation_gain, y = pace)) +
        geom_point() +
        geom_abline(slope = 0.1613, intercept = 361.6337)

```

It looks like elevation makes a difference.

Now let's consider my training prior to any particular run. To do this I'll first need to calculate my total distance during the twelve weeks prior to any particular run.

```{r training_model}
activities <- activities %>%
        complete(date = seq.Date(min(date), max(date), by="day")) %>%
        mutate(training = rollapply(Distance, width = list(-85:-1), sum, 
                                    align = "right", partial = TRUE, 
                                    na.rm = TRUE, fill = 0))

mod_training <- lm(pace ~ training, activities)
mod_training
anova(mod_training)
ggplot(activities, mapping = aes(x = training, y = pace)) +
        geom_point() +
        geom_abline(slope = -.03712, intercept = 387.6180)
```

So my pace does seem to drop with increased training, but maybe not as drastically as I would hope. Let's see what recovery days do to my pace.

```{r recovery_model}
activities <- activities %>%
        mutate(recovery = rollapply(Distance, width = list(-3:-1), sum, 
                                    align = "right", partial = TRUE, 
                                    na.rm = TRUE, fill = 0))

mod_recovery <- lm(pace ~ recovery, activities)
mod_recovery
anova(mod_recovery)
confint(mod_recovery)
ggplot(activities, mapping = aes(x = recovery, y = pace)) +
        geom_point() +
        geom_abline(slope = 0.2668, intercept = 374.8203)
```

So the more I ran in the previous two days, the slower I run on any given day, just as I would expect, but the result is not significant. 

Maybe training plus recovery together will produce a more meaningful model

```{r training_recovery}
mod_training_recovery <- lm(pace ~ training + recovery, activities)
mod_training_recovery
anova(mod_training_recovery)
```

It seems like they do.

So on their own, each of the variables considered above seems significant. Let's put them together and see what we get.

```{r first_overall_model}
mod_overall1 <- lm(pace ~ date + training + recovery + elevation_gain + 
                          Distance, activities)
mod_overall1
anova(mod_overall1)
```

The results here show up as statistically significant with the exception of distance. I suspect that if I exclude the outliers (three marathons), we'll get a more meaningful result.
 
```{r second_distance_model}
no_marathons <- activities %>%
        filter(Distance < 40)
mod_distance2 <- lm(pace ~ Distance, no_marathons)
mod_distance2
anova(mod_distance)
ggplot(no_marathons, mapping = aes(x = Distance, y = pace)) +
        geom_point() +
        geom_abline(slope = 0.6475, intercept = 372.2565)
```
 
 That made a difference, but maybe not as much as I expected. Let's see if our overall model behaves more like we would expect it to using this filtered data set.
 
```{r third_overall_model}
mod_overall3 <- lm(pace ~ date + training + recovery + elevation_gain + 
                          Distance, no_marathons)
mod_overall3
anova(mod_overall3)
confint(mod_overall3)
```
 
The results for Distance are still without statistical significance. There may just be too much noise around this variable. Many short runs are recovery runs. Many longer runs are races.

So far it seems like the second overall model provides the best tool for predicting pace. Let's return to the model and take a moment to evaluate its quality. 

```{r final_overall_model}
mod_overall <- lm(pace ~ date + training + recovery + elevation_gain, 
                   activities)
summary(mod_overall)
confint(mod_overall)

activities <- activities %>% 
  add_residuals(mod_overall)

ggplot(activities, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)

ggplot(activities, aes(pace, resid)) + 
  geom_ref_line(h = 0) +
  geom_point() 
```

This model seems like it's capturing significant patterns in the data, but the residuals remain skewed in an apparently linear pattern with faster paces being underestimated and slower paces being overestimated. I suspect that these results are simply a matter of important information that is not represented in the data set: races, workouts, easy runs, weather, etc. Sometimes I'm taking it easy and sometimes I'm going as fast as I can and those internal factors are not recorded in this data set.

If, however, I were only trying to predict race times, I might be able to get a more accurate model since I try to go as fast as I can when I'm racing.

Athlinks has a record of the races I've run during this time frame. There does not seem to be an obvious way to download this data, but it's not a big data set, so I can manually mark the races in my Strava data set. (Strava also has this information but did not include it in their .csv file)

```{r races}
races <- activities %>%
        filter(date == "2016-11-20" | 
                       date == "2017-11-05" |
                       date == "2017-11-05" | 
                       date == "2018-04-07" |
                       date == "2018-07-04" |
                       date == "2018-07-14" | 
                       date == "2018-08-04" |
                       date == "2018-10-21" |
                       date == "2018-11-22" |
                       date == "2019-03-09" |
                       date == "2019-04-06" |
                       date == "2019-07-04" |
                       date == "2019-10-20" |
                       date == "2019-11-28") %>%
        mutate(race = TRUE)


```

